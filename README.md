# GLOBE-CE: Global & Efficient Counterfactual Explanations

From the ICML 2023 paper [GLOBE-CE: A Translation-Based Approach for Global Counterfactual Explanations](https://arxiv.org/abs/2305.17021).

<img width="1308" alt="Screenshot 2023-12-17 at 2 30 08 PM" src="https://github.com/danwley/GLOBE-CE/assets/35569862/e3b6dfc3-201d-4c3f-a7b1-d48ae227b288">

Given recent requests, we have pushed the datasets, models and classes used in our experiments.

An implementation of the [AReS](https://arxiv.org/abs/2009.07165) method is also provided, including our enhancements as detailed in Appendix C.

Any questions regarding the method or implementation can be directed to Dan Ley (email address provided in the paper).

Please cite our paper if you find it useful in your research:

```
@inproceedings{ley2023globece,
  title={GLOBE-CE: A Translation-Based Approach for Global Counterfactual Explanations},
  author={Dan Ley and Saumitra Mishra and Daniele Magazzeni},
  booktitle={International Conference on Machine Learning},
  year={2023}
}
```
